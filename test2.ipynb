{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]],\n",
       "       dtype=torch.complex128)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3 # number of qubits\n",
    "\n",
    "state = th.zeros(2**N,2**N, dtype=th.complex128)\n",
    "state[7,7] = 1.0  # |000>\n",
    "\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(theta):\n",
    "    \"\"\"Rotation matrix for a single qubit.\"\"\"\n",
    "    U = th.tensor(\n",
    "            [[np.cos(theta / 2), -1j * np.sin(theta / 2)],\n",
    "            [-1j * np.sin(theta / 2), np.cos(theta / 2)]],\n",
    "            dtype=th.complex128)\n",
    "    return U\n",
    "\n",
    "\n",
    "def global_rotation(angles,N):\n",
    "    \"\"\"Apply a global rotation to the state vector.\"\"\"\n",
    "\n",
    "    U = rotation(angles[0])\n",
    "\n",
    "    for i in range(1,N):\n",
    "        U_i = rotation(angles[i])\n",
    "        U = th.kron(U, U_i)\n",
    "    return U\n",
    "\n",
    "\n",
    "def cnot_gate(state, N, k):\n",
    "    \"\"\"Apply a CNOT gate to the state vector. The CNOT act on qubit k and k+1.\"\"\"\n",
    "\n",
    "    cnot = th.tensor([\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 0, 1],\n",
    "                [0, 0, 1, 0]\n",
    "        ], dtype=th.complex128)\n",
    "    \n",
    "    p1 = k\n",
    "    p2 = N-k-2\n",
    "\n",
    "    Id1 = th.eye(2**p1, dtype=th.complex128)\n",
    "    Id2 = th.eye(2**p2, dtype=th.complex128)\n",
    "\n",
    "    cnot_matrix = th.kron(Id1, th.kron(cnot, Id2))\n",
    "    \n",
    "    return cnot_matrix @ state @ cnot_matrix.adjoint() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ghz_state(N):\n",
    "    \"\"\"Generate a GHZ state for N qubits.\"\"\"\n",
    "    ghz_state = th.zeros(2**N, dtype=th.complex128)\n",
    "    ghz_state[0] = 1 / th.sqrt(th.tensor(2.0, dtype=th.complex128))\n",
    "    ghz_state[-1] = 1 / th.sqrt(th.tensor(2.0, dtype=th.complex128))\n",
    "    return th.outer(ghz_state, ghz_state)\n",
    "\n",
    "\n",
    "def generate_H(N):\n",
    "    h = 9/N\n",
    "    scale = 2**(N/2)\n",
    "\n",
    "    Z = th.tensor([[1, 0], [0, -1]], dtype=th.complex128)\n",
    "\n",
    "    ZZ = th.kron(Z, Z)\n",
    "\n",
    "    H = th.zeros(2**N, 2**N, dtype=th.complex128)\n",
    "\n",
    "    for i in range(N-1):\n",
    "        H += th.kron( th.eye(2**i), th.kron(ZZ, th.eye(2**(N-i-2))) )\n",
    "\n",
    "    return h*scale*H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(state, angles, N):\n",
    "    \"\"\"Apply a layer of gates to the state vector.\"\"\"\n",
    "    U = global_rotation(angles,N)\n",
    "    \n",
    "    # Apply the rotation\n",
    "    state = U @ state @ U.adjoint()\n",
    "    \n",
    "    # Apply CNOT gates\n",
    "    for i in range(N-1):\n",
    "        state = cnot_gate(state, N, i)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def calc_variance(N,L,p):\n",
    "    n_sim = 1\n",
    "\n",
    "    ghz = generate_ghz_state(N)\n",
    "    H = generate_H(N)\n",
    "\n",
    "    obs = 0\n",
    "\n",
    "    for _ in range(n_sim):\n",
    "        state = th.zeros(2**N,2**N, dtype=th.complex128)\n",
    "        state[0,0] = 1.0  # |000>\n",
    "\n",
    "        params = np.random.uniform(0, np.pi, size=(L, N))\n",
    "\n",
    "        # Sample whether to entangle or use CNOT at each layer\n",
    "        entangle_flags = np.random.rand(L) < p  # Boolean array\n",
    "\n",
    "        for i, apply_entangled in enumerate(entangle_flags):\n",
    "            if apply_entangled:\n",
    "                state = ghz\n",
    "            else:\n",
    "                state = layer(state, params[i], N)\n",
    "\n",
    "        # Run the circuit\n",
    "        obs += th.trace(state @ H).real\n",
    "    \n",
    "    return obs/n_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-88.7017, dtype=torch.float64)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_variance(10, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
